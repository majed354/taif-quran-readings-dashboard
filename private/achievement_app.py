import streamlit as st
import pandas as pd
import requests
import base64
import io
import uuid
from datetime import datetime
import traceback
import time
import json
import os

# Simple test element added here
st.title("ØµÙØ­Ø© Ø§Ø®ØªØ¨Ø§Ø±")
st.write("Ø¥Ø°Ø§ Ø±Ø£ÙŠØª Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø©ØŒ ÙØ¥Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ.")

# -------------------------------------------------------------------------
# Ø§Ù„ÙØ¦Ø§Øª
CATEGORIES = {
    "CURR": "ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬",
    "TEAC": "Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„ØªÙ‚ÙˆÙŠÙ…",
    "QUAL": "Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ ÙˆØ§Ù„Ø¬ÙˆØ¯Ø©",
    "RESR": "Ø¨Ø­Ø« Ø¹Ù„Ù…ÙŠ ÙˆÙ†Ø´Ø±",
    "EVNT": "ÙØ¹Ø§Ù„ÙŠØ§Øª ÙˆØ®Ø¯Ù…Ø© Ù…Ø¬ØªÙ…Ø¹",
    "STUD": "Ø¯Ø¹Ù… ÙˆØ®Ø¯Ù…Ø§Øª Ø·Ù„Ø§Ø¨ÙŠØ©",
    "ADMN": "Ù…Ù‡Ø§Ù… Ø¥Ø¯Ø§Ø±ÙŠØ©",
    "PDVL": "ØªØ·ÙˆÙŠØ± Ù…Ù‡Ù†ÙŠ"
}

# -------------------------------------------------------------------------
# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© -----------------------------------------------------------
# Note: st.set_page_config must be the first Streamlit command.
# Moved the test title after set_page_config.
st.set_page_config("Ù„ÙˆØ­Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª", layout="centered")

# Re-add the test elements after set_page_config
st.title("ØµÙØ­Ø© Ø§Ø®ØªØ¨Ø§Ø±")
st.write("Ø¥Ø°Ø§ Ø±Ø£ÙŠØª Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø©ØŒ ÙØ¥Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ.")


# CSS Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700&display=swap');

    * {
        font-family: 'Tajawal', sans-serif !important;
    }
    body, .stApp {
        direction: rtl;
        text-align: right;
    }
    button, input, select, textarea {
        text-align: right;
    }
    .stTabs [data-baseweb="tab-list"] {
        direction: rtl;
    }
    h1, h2, h3, h4, h5, h6 {
        text-align: right;
    }
    .stButton>button {
        background-color: #1e88e5;
        color: white;
        border-radius: 6px;
        padding: 8px 16px;
        font-weight: 600;
    }
    .stButton>button:hover {
        background-color: #1565c0;
    }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------------------
# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ---------------------------------------------------------
def show_error(error_msg, details=None):
    st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {error_msg}")
    if details:
        with st.expander("ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ (Ù„Ù„Ù…Ø·ÙˆØ±ÙŠÙ†)"):
            st.code(details)

# -------------------------------------------------------------------------
# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© --------------------------------------------
def check_environment():
    try:
        # ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
        required_vars = ["GITHUB_TOKEN", "REPO_NAME", "MASTER_PASS", "DEESEEK_KEY"]
        missing_vars = []

        for var in required_vars:
            # Check if secrets are loaded and the variable exists
            if not hasattr(st, 'secrets') or var not in st.secrets:
                 missing_vars.append(var)

        if missing_vars:
            show_error(
                f"Ø¨Ø¹Ø¶ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø±Ø§Ø±: {', '.join(missing_vars)}",
                "ÙŠØ¬Ø¨ Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø¥Ù„Ù‰ Ù…Ù„Ù .streamlit/secrets.toml Ø£Ùˆ ØªÙƒÙˆÙŠÙ†Ù‡Ø§ ÙƒØ£Ø³Ø±Ø§Ø± ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ù†Ø´Ø±."
            )
            return False
        return True
    except Exception as e:
        show_error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©", traceback.format_exc()) # Use traceback for more details
        return False

# -------------------------------------------------------------------------
# Ø£Ø¯ÙˆØ§Øª GitHub ------------------------------------------------------------
@st.cache_resource(ttl=3600) # Cache the GitHub connection for an hour
def get_github_instance():
    """Initializes and returns the GitHub instance."""
    try:
        from github import Github, Auth
        # Use Auth.Token for explicit token authentication
        auth = Auth.Token(st.secrets["GITHUB_TOKEN"])
        return Github(auth=auth)
    except ImportError:
        st.error("Ù…ÙƒØªØ¨Ø© PyGithub ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØªÙ‡Ø§: pip install PyGithub")
        return None
    except Exception as e:
        show_error("Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§ØªØµØ§Ù„ GitHub", traceback.format_exc())
        return None

@st.cache_data(ttl=600) # Cache repository object for 10 minutes
def gh_repo(_gh_instance):
    """Gets the repository object using a cached GitHub instance."""
    if not _gh_instance:
        return None
    try:
        return _gh_instance.get_repo(st.secrets["REPO_NAME"])
    except Exception as e:
        # Reset specific caches if repo access fails
        st.cache_data.clear()
        show_error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆØ¯Ø¹ GitHub Ø§Ù„Ù…Ø­Ø¯Ø¯", traceback.format_exc())
        return None

# Pass the GitHub instance to functions that need it
def load_csv(path: str, _repo):
    """Loads a CSV file from the GitHub repository."""
    if not _repo:
        return pd.DataFrame(), None
    try:
        file = _repo.get_contents(path)
        # Ensure content is treated as bytes before decoding
        content_bytes = base64.b64decode(file.content)
        data = content_bytes.decode("utf-8-sig") # Use utf-8-sig to handle BOM
        return pd.read_csv(io.StringIO(data)), file.sha
    except Exception as e: # Catch specific GithubException for 'Not Found'
        from github import UnknownObjectException
        if isinstance(e, UnknownObjectException):
             st.warning(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù: {path} - Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø¹Ù†Ø¯ Ø§Ù„Ø­ÙØ¸.")
             return pd.DataFrame(), None # Return empty DataFrame and None sha
        else:
             show_error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {path}", traceback.format_exc())
             # Clear cache on error to force reload next time
             st.cache_data.clear()
             return pd.DataFrame(), None


def save_csv(path: str, df: pd.DataFrame, sha: str | None, msg: str, _repo):
    """Saves a DataFrame to a CSV file in the GitHub repository."""
    if not _repo:
        return False
    try:
        # Ensure line terminator is \n for consistency
        content = df.to_csv(index=False, line_terminator="\n", encoding="utf-8-sig") # Use utf-8-sig

        # Check if the file exists before trying to update
        file_exists = True
        try:
            # If sha is not provided, try to get the current file to check existence and get sha
            if not sha:
                current_file = _repo.get_contents(path)
                sha = current_file.sha
        except Exception: # Specifically catch UnknownObjectException if possible
             from github import UnknownObjectException
             # If getting contents fails, assume file doesn't exist
             file_exists = False
             sha = None # Ensure sha is None if file doesn't exist


        if file_exists and sha:
             _repo.update_file(path, msg, content, sha)
             st.success(f"ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù: {path}")
        else:
             # Create the file if it doesn't exist
             _repo.create_file(path, msg, content)
             st.success(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: {path}")

        # Clear relevant caches after successful save
        st.cache_data.clear()
        # Optionally clear resource cache if repo structure might change significantly
        # st.cache_resource.clear()
        return True

    except Exception as e:
        show_error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {path}", traceback.format_exc())
        return False


def year_path(y:int):         # Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ù„Ù„Ø³Ù†Ø©
    # Use os.path.join for cross-platform compatibility, though GitHub uses forward slashes
    return f"data/department/{y}/achievements_{y}.csv"

# -------------------------------------------------------------------------
# ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù‡Ø§Ù… (ÙˆØ¸ÙŠÙØ© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ DeepSeek) ----------------------
def fallback_classification(text:str)->dict:
    # ØªØµÙ†ÙŠÙ Ø¨Ø³ÙŠØ· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
    text_lower = text.lower() # Convert to lowercase for case-insensitive matching
    category_code = "PDVL" # Default category

    # Define keywords for each category
    keywords = {
        "RESR": ["Ø¨Ø­Ø«", "Ù†Ø´Ø±", "Ù…Ù‚Ø§Ù„Ø©", "Ù…Ø¤ØªÙ…Ø±", "Ù…Ø¬Ù„Ø©", "Ø¯Ø±Ø§Ø³Ø©", "Ø¹Ù„Ù…ÙŠ"],
        "CURR": ["Ù…Ù‚Ø±Ø±", "Ù…Ù†Ù‡Ø¬", "ØªØ·ÙˆÙŠØ±", "Ù…Ø§Ø¯Ø©", "Ø®Ø·Ø© Ø¯Ø±Ø§Ø³ÙŠØ©", "ÙˆØµÙ Ù…Ù‚Ø±Ø±"],
        "TEAC": ["ØªØ¹Ù„ÙŠÙ…", "ØªØ¯Ø±ÙŠØ³", "Ù…Ø­Ø§Ø¶Ø±", "ØªÙ‚ÙˆÙŠÙ…", "Ø§Ø®ØªØ¨Ø§Ø±", "ÙˆØ±Ø´Ø© Ø¹Ù…Ù„ ØªØ¯Ø±ÙŠØ³ÙŠØ©"],
        "QUAL": ["Ø¬ÙˆØ¯Ø©", "Ø§Ø¹ØªÙ…Ø§Ø¯", "ØªÙ‚ÙŠÙŠÙ…", "Ù…Ø±Ø§Ø¬Ø¹Ø©", "Ù…Ø¹Ø§ÙŠÙŠØ±", "ØªØ­Ø³ÙŠÙ†"],
        "EVNT": ["Ø®Ø¯Ù…Ø©", "Ù…Ø¬ØªÙ…Ø¹", "ÙØ¹Ø§Ù„ÙŠØ©", "Ù†Ø´Ø§Ø·", "Ù…Ø¨Ø§Ø¯Ø±Ø©", "ØªØ·ÙˆØ¹", "Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ø¬ØªÙ…Ø¹ÙŠØ©"],
        "STUD": ["Ø·Ù„Ø§Ø¨", "Ø·Ø§Ù„Ø¨", "Ø¥Ø±Ø´Ø§Ø¯", "Ø¯Ø¹Ù… Ø·Ù„Ø§Ø¨ÙŠ", "Ø£Ù†Ø´Ø·Ø© Ø·Ù„Ø§Ø¨ÙŠØ©"],
        "ADMN": ["Ø¥Ø¯Ø§Ø±Ø©", "Ù„Ø¬Ù†Ø©", "Ø§Ø¬ØªÙ…Ø§Ø¹", "ØªÙ†Ø¸ÙŠÙ…", "ØªÙ†Ø³ÙŠÙ‚", "ØªÙ‚Ø±ÙŠØ± Ø¥Ø¯Ø§Ø±ÙŠ"]
    }

    # Find the best matching category
    for code, words in keywords.items():
        if any(word in text_lower for word in words):
            category_code = code
            break # Stop after finding the first match

    # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø³Ø§Ø¹Ø§Øª
    word_count = len(text.split())
    # Simple estimation: 1 hour per 10 words, capped between 2 and 40 hours
    virtual_hours = max(2, min(40, word_count // 10 + 1))
    # Simple points: 2 points per hour
    points = virtual_hours * 2

    return {
        "points": points,
        "virtual_hours": virtual_hours,
        "category_code": category_code,
        "category_label": CATEGORIES.get(category_code, "ØºÙŠØ± Ù…ØµÙ†Ù") # Use .get for safety
    }

# -------------------------------------------------------------------------
# DeepSeek (Ø§Ù„ØªØµÙ†ÙŠÙ + Ø§Ù„Ù†Ù‚Ø§Ø·) --------------------------------------------
@st.cache_data(ttl=3600) # Cache DeepSeek results for an hour
def deepseek_eval(text:str)->dict:
    """Evaluates achievement text using DeepSeek API or fallback."""
    try:
        # Ensure DEESEEK_KEY is available
        if "DEESEEK_KEY" not in st.secrets:
            st.warning("Ù…ÙØªØ§Ø­ DeepSeek API ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
            return fallback_classification(text)

        api_key = st.secrets['DEESEEK_KEY']
        api_url = "https://api.deepseek.com/v1/chat/completions"

        # Construct the prompt with clear instructions and categories
        system_prompt = (
            "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© Ø¶Ù…Ù† Ø³ÙŠØ§Ù‚ Ø¬Ø§Ù…Ø¹ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ù‚Ø±Ø§Ø¡Ø© ÙˆØµÙ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ù„Ø§Ø¡Ù…Ø© Ù„Ù‡ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©ØŒ ÙˆØªÙ‚Ø¯ÙŠØ± Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø§Ù„ØªÙŠ ÙŠØ³ØªØ­Ù‚Ù‡Ø§ Ù‡Ø°Ø§ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù‡Ù…ÙŠØªÙ‡ ÙˆØ§Ù„Ø¬Ù‡Ø¯ Ø§Ù„Ù…Ø¨Ø°ÙˆÙ„ ÙÙŠÙ‡.\n\n"
            "Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ø¹ Ø±Ù…ÙˆØ²Ù‡Ø§:\n"
            + "\n".join([f"- {code}: {label}" for code, label in CATEGORIES.items()]) + "\n\n"
            "Ø£Ø¹Ø¯ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON ØªØ­ØªÙˆÙŠ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ©:\n"
            "- points (integer): ØªÙ‚Ø¯ÙŠØ± Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· (Ù…Ø«Ù„Ø§Ù‹: Ø¨ÙŠÙ† 5 Ùˆ 100 Ù†Ù‚Ø·Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©).\n"
            "- virtual_hours (integer): ØªÙ‚Ø¯ÙŠØ± Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (Ù…Ø«Ù„Ø§Ù‹: Ø¨ÙŠÙ† 2 Ùˆ 60 Ø³Ø§Ø¹Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù‡Ø¯).\n"
            "- category_code (string): Ø±Ù…Ø² Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡.\n"
            "- category_label (string): Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø±Ù…Ø².\n\n"
            "Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {\"points\": 25, \"virtual_hours\": 15, \"category_code\": \"RESR\", \"category_label\": \"Ø¨Ø­Ø« Ø¹Ù„Ù…ÙŠ ÙˆÙ†Ø´Ø±\"}"
        )

        payload = {
            "model": "deepseek-chat", # Use the appropriate model
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ÙŠØ±Ø¬Ù‰ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„ØªØ§Ù„ÙŠ:\n\n{text}"}
            ],
            "temperature": 0.5, # Adjust temperature for more deterministic results if needed
            "max_tokens": 200, # Set a reasonable max token limit for the response
            "response_format": {"type": "json_object"} # Request JSON output directly if supported
        }

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        # Make the API call with a timeout
        r = requests.post(api_url, headers=headers, json=payload, timeout=30) # Increased timeout
        r.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)

        response_data = r.json()

        # Extract the JSON content from the response
        if response_data.get("choices") and response_data["choices"][0].get("message"):
             content = response_data["choices"][0]["message"].get("content")
             if content:
                 try:
                     # Parse the JSON string from the content
                     result = json.loads(content)
                     # Validate the result structure
                     if all(k in result for k in ["points", "virtual_hours", "category_code", "category_label"]):
                          # Ensure the category code is valid
                          if result["category_code"] in CATEGORIES:
                              # Re-assign label from our definition for consistency
                              result["category_label"] = CATEGORIES[result["category_code"]]
                              return result
                          else:
                              st.warning(f"DeepSeek Ø£Ø¹Ø§Ø¯ Ø±Ù…Ø² ÙØ¦Ø© ØºÙŠØ± ØµØ§Ù„Ø­: {result['category_code']}. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
                              return fallback_classification(text)
                     else:
                          st.warning("Ø§Ø³ØªØ¬Ø§Ø¨Ø© DeepSeek JSON ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
                          return fallback_classification(text)
                 except json.JSONDecodeError:
                      st.warning("ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© JSON Ù…Ù† DeepSeek. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
                      return fallback_classification(text)
             else:
                  st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ ÙÙŠ Ø§Ø³ØªØ¬Ø§Ø¨Ø© DeepSeek. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
                  return fallback_classification(text)
        else:
             st.warning("Ø§Ø³ØªØ¬Ø§Ø¨Ø© DeepSeek ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø©. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
             return fallback_classification(text)

    except requests.exceptions.Timeout:
        st.warning("Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ DeepSeek API. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
        return fallback_classification(text)
    except requests.exceptions.RequestException as e:
        st.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ DeepSeek API: {e}. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
        return fallback_classification(text)
    except Exception as e:
        st.warning(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© DeepSeek: {e}. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ.")
        # Log the full traceback for debugging if needed
        # show_error("Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ DeepSeek", traceback.format_exc())
        return fallback_classification(text)


# -------------------------------------------------------------------------
# Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---------------------------------------------------------

# Initialize session state keys if they don't exist
if "auth" not in st.session_state:
    st.session_state.auth = False
if "member_name" not in st.session_state:
    st.session_state.member_name = ""
if "selected_year" not in st.session_state:
    st.session_state.selected_year = datetime.now().year
if "main_task_choice" not in st.session_state:
     st.session_state.main_task_choice = "â€” Ø§Ø®ØªØ± Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© â€”" # Initial default


# --- Authentication ---
if not st.session_state.auth:
    st.header("ğŸ”’ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„") # Use header for better structure
    # Check environment variables needed for login first
    env_ok = True
    if "MASTER_PASS" not in st.secrets:
         st.error("Ù…ØªØºÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (MASTER_PASS) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø£Ø³Ø±Ø§Ø±.")
         env_ok = False

    if env_ok:
         pw = st.text_input("ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ø¹Ø§Ù…Ø©", type="password", key="login_pw")
         if st.button("Ø¯Ø®ÙˆÙ„", key="login_button"):
             if pw == st.secrets.get("MASTER_PASS"): # Use .get for safety
                 st.session_state.auth = True
                 st.success("ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
                 time.sleep(1)
                 st.rerun() # Use st.rerun instead of experimental_rerun
             else:
                 st.error("ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©!")
    else:
         st.warning("ÙŠØ±Ø¬Ù‰ ØªÙƒÙˆÙŠÙ† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„.")
    st.stop() # Stop execution if not authenticated

# --- Main Application Logic (runs only if authenticated) ---

# Initialize GitHub connection (cached)
gh_instance = get_github_instance()
if not gh_instance:
     st.error("ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ GitHub. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©.")
     st.stop()

repo = gh_repo(gh_instance) # Get repo object (cached)
if not repo:
     st.error("ÙØ´Ù„ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ ÙˆØ§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª.")
     st.stop()


# --- Sidebar for User Info ---
with st.sidebar:
    st.header("ğŸ‘¤ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
    # Use session state to preserve name and year across reruns
    st.session_state.member_name = st.text_input(
        "Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ",
        value=st.session_state.member_name,
        key="member_name_input"
    )
    st.session_state.selected_year = st.number_input(
        "Ø§Ù„Ø³Ù†Ø©",
        min_value=2010,
        max_value=datetime.now().year + 1, # Allow next year
        value=st.session_state.selected_year,
        step=1,
        key="year_input"
    )

    st.markdown("---") # Separator
    if st.button("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬", key="logout_button"):
        # Clear relevant session state on logout
        st.session_state.auth = False
        st.session_state.member_name = ""
        # Optionally reset other state if needed
        # st.session_state.main_task_choice = "â€” Ø§Ø®ØªØ± Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© â€”"
        st.cache_data.clear() # Clear data cache on logout
        st.cache_resource.clear() # Clear resource cache (like GitHub connection)
        st.rerun()

# Check if member name is entered
if not st.session_state.member_name.strip():
    st.info("ğŸ‘ˆ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù…Ùƒ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©.")
    st.stop()

# Assign state values to local variables for easier use
member = st.session_state.member_name
year = st.session_state.selected_year


# --- Main Task Selection ---
st.header("ğŸ¯ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
try:
    main_tasks_path = "data/main_tasks.csv"
    main_df, main_sha = load_csv(main_tasks_path, repo)

    # Initialize DataFrame if it's empty or doesn't exist
    if main_df.empty:
        main_df = pd.DataFrame(columns=["id", "title", "descr"])
        main_sha = None # Ensure sha is None if file was just created in memory

    # Ensure required columns exist
    if "title" not in main_df.columns: main_df["title"] = ""
    if "id" not in main_df.columns: main_df["id"] = ""
    if "descr" not in main_df.columns: main_df["descr"] = ""


    titles = main_df["title"].tolist()
    options = ["â€” Ø§Ø®ØªØ± Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© â€”"] + sorted([t for t in titles if t]) + ["â• Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© Ø±Ø¦ÙŠØ³ÙŠØ©â€¦"] # Sort titles

    # Use session state for the selectbox choice
    st.session_state.main_task_choice = st.selectbox(
         "Ø§Ø®ØªØ± Ø£Ùˆ Ø£Ø¶Ù Ù…Ù‡Ù…Ø© Ø±Ø¦ÙŠØ³ÙŠØ©",
         options,
         index=options.index(st.session_state.main_task_choice) if st.session_state.main_task_choice in options else 0,
         key="main_task_selectbox"
     )
    choice = st.session_state.main_task_choice


    main_id = None # Initialize main_id

    if choice == "â• Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© Ø±Ø¦ÙŠØ³ÙŠØ©â€¦":
        st.subheader("â• Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©")
        with st.form("add_main_task_form"):
            new_title = st.text_input("Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‡Ù…Ø©")
            new_descr = st.text_area("ÙˆØµÙ Ù…Ø®ØªØµØ± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
            submitted = st.form_submit_button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")

            if submitted:
                if not new_title.strip():
                    st.warning("Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ø·Ù„ÙˆØ¨.")
                elif new_title in titles:
                     st.warning("Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„ÙØ¹Ù„.")
                else:
                    new_id = str(uuid.uuid4())[:8]
                    # Use pd.concat instead of .loc for adding rows
                    new_row = pd.DataFrame([{"id": new_id, "title": new_title, "descr": new_descr}])
                    main_df = pd.concat([main_df, new_row], ignore_index=True)

                    if save_csv(main_tasks_path, main_df, main_sha, f"Add main task: {new_title}", repo):
                        st.success(f"ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {new_title}")
                        # Update state and rerun
                        st.session_state.main_task_choice = new_title # Select the newly added task
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­ÙØ¸ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.")
                        # Revert DataFrame if save failed
                        main_df = main_df[:-1]


    elif choice.startswith("â€”"):
        st.warning("ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ù…Ù‡Ù…Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡ Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© ÙˆØ§Ø­Ø¯Ø© Ø¬Ø¯ÙŠØ¯Ø©.")
        st.stop()
    else:
        # Find the ID for the selected task
        task_row = main_df[main_df["title"] == choice]
        if not task_row.empty:
             main_id = task_row["id"].iloc[0]
             # Display description if available
             description = task_row["descr"].iloc[0]
             if pd.notna(description) and description.strip():
                  st.caption(f"ÙˆØµÙ Ø§Ù„Ù…Ù‡Ù…Ø©: {description}")
        else:
             st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©.")
             st.stop()


except Exception as e:
    show_error("Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", traceback.format_exc())
    st.stop()

# Stop if no valid main task is selected
if not main_id:
     st.warning("Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù‡Ù…Ø© Ø±Ø¦ÙŠØ³ÙŠØ© ØµØ§Ù„Ø­Ø©.")
     st.stop()


# --- Load/Display Member's Achievements for the Year ---
st.header(f"âœï¸ Ø¥Ù†Ø¬Ø§Ø²Ø§ØªÙƒ Ù„Ø¹Ø§Ù… {year}")
achievement_file_path = year_path(year)
df, sha = load_csv(achievement_file_path, repo)

# Define expected columns
expected_cols = ["Ø§Ù„Ø¹Ø¶Ùˆ", "Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ù†Ù‚Ø§Ø·", "Ø§Ù„ÙØ¦Ø©", "Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©", "main_id"]

# Initialize DataFrame if empty or file not found
if df.empty:
    df = pd.DataFrame(columns=expected_cols)
    sha = None # Ensure sha is None if df is newly created

# Ensure all expected columns exist, add if missing
for col in expected_cols:
     if col not in df.columns:
          df[col] = pd.NA # Add missing column with NA values


# Filter tasks for the current member and selected main task
my_tasks = df[(df["Ø§Ù„Ø¹Ø¶Ùˆ"] == member) & (df["main_id"] == main_id)].copy() # Filter and create a copy
my_tasks = my_tasks.sort_values(by="Ø§Ù„ØªØ§Ø±ÙŠØ®", ascending=False).reset_index(drop=True) # Sort by date


if my_tasks.empty:
    st.caption(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ù…Ø³Ø¬Ù„Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ({choice}) ÙÙŠ Ø¹Ø§Ù… {year}.")
else:
    st.write(f"Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ø§Ù„Ù…Ø³Ø¬Ù„Ø© Ù„Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: **{choice}**")
    # Display tasks with delete buttons
    for i in my_tasks.index:
        task_col, date_col, points_col, delete_col = st.columns([5, 2, 1, 1]) # Adjust column ratios

        with task_col:
            achievement = my_tasks.loc[i, 'Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²']
            st.markdown(f"**{achievement}**")

        with date_col:
             task_date = my_tasks.loc[i, 'Ø§Ù„ØªØ§Ø±ÙŠØ®']
             st.caption(f"Ø§Ù„ØªØ§Ø±ÙŠØ®: {task_date}")


        with points_col:
            points = my_tasks.loc[i, 'Ø§Ù„Ù†Ù‚Ø§Ø·']
            hours = my_tasks.loc[i, 'Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©']
            category = my_tasks.loc[i, 'Ø§Ù„ÙØ¦Ø©']
            st.caption(f"{points} Ù†Ù‚Ø·Ø© | {hours} Ø³ | {category}")


        with delete_col:
            # Use the original DataFrame index for deletion
            original_index = df[(df["Ø§Ù„Ø¹Ø¶Ùˆ"] == member) &
                                (df["main_id"] == main_id) &
                                (df["Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] == achievement) & # Add more conditions if needed for uniqueness
                                (df["Ø§Ù„ØªØ§Ø±ÙŠØ®"] == task_date)].index

            if not original_index.empty:
                 # Generate a unique key for the button based on the original index
                 delete_key = f"del-{original_index[0]}"
                 if st.button("ğŸ—‘ï¸ Ø­Ø°Ù", key=delete_key, help="Ø­Ø°Ù Ù‡Ø°Ø§ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"):
                     # Get the latest sha before deleting
                     _, current_sha = load_csv(achievement_file_path, repo)
                     if current_sha: # Proceed only if sha is available
                          df_to_save = df.drop(original_index[0]).reset_index(drop=True)
                          if save_csv(achievement_file_path, df_to_save, current_sha, f"Delete achievement by {member}", repo):
                              st.success("ØªÙ… Ø­Ø°Ù Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø¨Ù†Ø¬Ø§Ø­.")
                              time.sleep(1)
                              st.rerun()
                          else:
                              st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­Ø°Ù Ø§Ù„Ø¥Ù†Ø¬Ø§Ø².")
                     else:
                          st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ SHA. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø­Ø°Ù.")

            else:
                 st.error("Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø£ØµÙ„ÙŠ Ù„Ù„Ù…Ù‡Ù…Ø©.")


# --- Add New Achievement Form ---
st.markdown("---")
st.header("â• Ø¥Ø¶Ø§ÙØ© Ø¥Ù†Ø¬Ø§Ø² Ø¬Ø¯ÙŠØ¯")
st.write(f"Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©: **{choice}**")


with st.form("add_achievement_form", clear_on_submit=True):
    # Default to today's date, ensure it's within the selected year
    today = datetime.now().date()
    default_date = today if today.year == year else datetime(year, 1, 1).date()
    min_date = datetime(year, 1, 1).date()
    max_date = datetime(year, 12, 31).date()

    date = st.date_input("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", value=default_date, min_value=min_date, max_value=max_date)
    desc = st.text_area("ÙˆØµÙ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²/Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ù†Ø¬Ø²Ø©", height=150, placeholder="Ø§ÙƒØªØ¨ ÙˆØµÙØ§Ù‹ ØªÙØµÙŠÙ„ÙŠØ§Ù‹ Ù„Ù„Ø¥Ù†Ø¬Ø§Ø² Ù‡Ù†Ø§...")
    submitted = st.form_submit_button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²")

if submitted:
    if not desc.strip():
        st.error("ÙˆØµÙ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ù…Ø·Ù„ÙˆØ¨.")
    elif not date:
         st.error("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ù…Ø·Ù„ÙˆØ¨.")
    elif date.year != year:
         st.error(f"ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø¶Ù…Ù† Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ({year}).")
    else:
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªÙ‚ÙŠÙŠÙ… ÙˆØ­ÙØ¸ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²..."):
            try:
                # Evaluate the achievement
                eva = deepseek_eval(desc) # This function now handles errors and fallback

                # Get the latest data and sha before appending
                df_current, current_sha = load_csv(achievement_file_path, repo)
                # Re-initialize if df_current is empty
                if df_current.empty:
                     df_current = pd.DataFrame(columns=expected_cols)
                     current_sha = None # SHA is None for a new file

                 # Ensure all columns exist in df_current
                for col in expected_cols:
                     if col not in df_current.columns:
                          df_current[col] = pd.NA


                # Create a new row as a DataFrame
                new_row_df = pd.DataFrame([{
                    "Ø§Ù„Ø¹Ø¶Ùˆ": member,
                    "Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²": desc,
                    "Ø§Ù„ØªØ§Ø±ÙŠØ®": date.isoformat(), # Store date as ISO string
                    "Ø§Ù„Ù†Ù‚Ø§Ø·": eva.get("points", 0), # Use .get with default
                    "Ø§Ù„ÙØ¦Ø©": eva.get("category_label", "ØºÙŠØ± Ù…ØµÙ†Ù"),
                    "Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©": eva.get("virtual_hours", 0),
                    "main_id": main_id
                }])

                # Concatenate the new row
                df_updated = pd.concat([df_current, new_row_df], ignore_index=True)

                # Save the updated DataFrame
                if save_csv(achievement_file_path, df_updated, current_sha, f"Add achievement by {member} ({date}) for task {main_id}", repo):
                    st.success(
                        f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø¨Ù†Ø¬Ø§Ø­!\n"
                        f"ğŸ“Š Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {eva.get('points', 'N/A')} Ù†Ù‚Ø·Ø©ØŒ "
                        f"{eva.get('virtual_hours', 'N/A')} Ø³Ø§Ø¹Ø©ØŒ "
                        f"Ø§Ù„ÙØ¦Ø©: {eva.get('category_label', 'N/A')}"
                    )
                    time.sleep(2) # Slightly longer pause for success message
                    st.rerun()
                else:
                    st.error("âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø². ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

            except Exception as e:
                show_error("Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", traceback.format_exc())

```

Ù„Ù‚Ø¯ Ø£Ø¶ÙØª `st.title("ØµÙØ­Ø© Ø§Ø®ØªØ¨Ø§Ø±")` Ùˆ `st.write(...)` Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¹Ø¯ `st.set_page_config`. Ø¬Ø±Ø¨ ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø¢Ù†. Ø¥Ø°Ø§ Ø±Ø£ÙŠØª Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù†ØµØŒ ÙÙ‡Ø°Ø§ ÙŠØ¤ÙƒØ¯ Ø£Ù† Ø¨ÙŠØ¦Ø© Streamlit ØªØ¹Ù…Ù„ ÙˆØ§Ù„Ø±Ø§Ø¨Ø· ØµØ­ÙŠØ­. Ø¥Ø°Ø§ Ù„Ù… ØªØ¸Ù‡Ø±ØŒ ÙÙ‚Ø¯ ØªÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Streamlit Ù†ÙØ³Ù‡Ø§ Ø£Ùˆ ÙÙŠ ÙƒÙŠÙÙŠØ© ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨
